{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "\n",
    "**Name** : Birat Gautam \n",
    "\n",
    "**Student ID** : 24128425\n",
    "\n",
    "**Course ID** : CMP5367\n",
    "\n",
    "**University** : Birmingham City University\n",
    "\n",
    "**Special Thanks** : Lecturer Prakash Gautam Sir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Left For Learning\n",
    "\n",
    "**Transparancy Vs Accuracy Trade Off**\n",
    "\n",
    "[Link1](https://www.youtube.com/watch?v=6mLJb5AWAMs)\n",
    "\n",
    "[Link2](https://www.youtube.com/watch?v=jNfLKLb6-GM)\n",
    "\n",
    "[Link3](https://www.youtube.com/watch?v=VY7SCl_DFho)\n",
    "\n",
    "[Link4](https://www.youtube.com/watch?v=tB3IWHT4FT4)\n",
    "\n",
    "[Link5](https://www.youtube.com/watch?v=Swm91MaisLg)\n",
    "\n",
    "[Medium_Article_Link](https://medium.com/towards-data-science/the-accuracy-vs-interpretability-trade-off-is-a-lie-0bf89c84f5b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.sysconfig.get_build_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Perform a large operation\n",
    "print(tf.reduce_sum(tf.random.normal([10000, 10000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Perform a simple operation\n",
    "a = tf.constant([[1.0, 2.0]])\n",
    "b = tf.constant([[3.0], [4.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with U-Net\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNEL = 3\n",
    "\n",
    "# Build the model\n",
    "\n",
    "# Encoding/contraction\n",
    "# Create tensor to hold the input image\n",
    "# First block of U-Net\n",
    "inputs = tf.keras.layers.Input((IMG_WIDTH,IMG_HEIGHT,IMG_CHANNEL))\n",
    "\n",
    "# Create Conv layer object and call the __call__ method with (inputs) as argument \n",
    "c1 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "\n",
    "# Add some drop out for regularization\n",
    "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "\n",
    "# Keras layers only accept floating value but pixels are integer, so it internally converts the input into float32\n",
    "\n",
    "# Check data types\n",
    "print(\"Input dtype:\", inputs.dtype)  # float32 due to keras\n",
    "print(\"Output dtype:\", c1.dtype)    # float32\n",
    "\n",
    "# 2nd Conv Layer\n",
    "c1 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "\n",
    "# Max-Pooling Layer with kernel size (2,2) and stride 2 by default\n",
    "p1 = tf.keras.layers.MaxPooling2D((2,2))(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second block of U-Net\n",
    "c2 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "\n",
    "# Add some drop out for regularization\n",
    "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "\n",
    "# 2nd Conv Layer\n",
    "c2 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "\n",
    "# Max-Pooling Layer\n",
    "p2 = tf.keras.layers.MaxPooling2D((2,2))(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third block of U-Net\n",
    "c3 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "\n",
    "# Add some drop out for regularization\n",
    "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "\n",
    "# 2nd Conv Layer\n",
    "c3 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "\n",
    "# Max-Pooling Layer\n",
    "p3 = tf.keras.layers.MaxPooling2D((2,2))(c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forth block of U-Net\n",
    "c4 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "\n",
    "# Add some drop out for regularization\n",
    "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "\n",
    "# 2nd Conv Layer\n",
    "c4 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "\n",
    "# Max-Pooling Layer\n",
    "p4 = tf.keras.layers.MaxPooling2D((2,2))(c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fifth block of U-Net\n",
    "c5 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "\n",
    "# Add some drop out for regularization\n",
    "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
    "\n",
    "# 2nd Conv Layer\n",
    "c5 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "# Shape after final Conv2D\n",
    "print(c5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the final Conv2D the output shape will be (8,8,256)\n",
    "\n",
    "# Decoding/Expansion\n",
    "\n",
    "# Sixth block of U-Net\n",
    "# Conv2DTranspose with kernel (2,2) and strides (2,2) \n",
    "# Upsamples the feature map by 2x in both height and width\n",
    "u6 = tf.keras.layers.Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c5)\n",
    "\n",
    "# Concatenation \n",
    "u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "\n",
    "# 1nd Conv Layer \n",
    "c6 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "\n",
    "# Add some drop out for regularization\n",
    "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "\n",
    "# 2nd Conv Layer\n",
    "c6 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seventh block of U-Net\n",
    "\n",
    "# Conv2DTranspose with kernel (2,2) and strides (2,2) \n",
    "# Upsamples the feature map by 2x in both height and width\n",
    "u7 = tf.keras.layers.Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c6)\n",
    "\n",
    "# Concatenation \n",
    "u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "\n",
    "# 1nd Conv Layer \n",
    "c7 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "\n",
    "# Add some drop out for regularization\n",
    "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "\n",
    "# 2nd Conv Layer\n",
    "c7 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eight block of U-Net\n",
    "\n",
    "# Conv2DTranspose with kernel (2,2) and strides (2,2) \n",
    "# Upsamples the feature map by 2x in both height and width\n",
    "u8 = tf.keras.layers.Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c7)\n",
    "\n",
    "# Concatenation \n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "\n",
    "# 1nd Conv Layer \n",
    "c8 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "\n",
    "# Add some drop out for regularization\n",
    "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "\n",
    "# 2nd Conv Layer\n",
    "c8 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ninth block of U-Net\n",
    "\n",
    "# Conv2DTranspose with kernel (2,2) and strides (2,2) \n",
    "# Upsamples the feature map by 2x in both height and width\n",
    "u9 = tf.keras.layers.Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(c8)\n",
    "\n",
    "# Concatenation \n",
    "u9 = tf.keras.layers.concatenate([u9, c1], axis=3) # Concatenate the channel axis (N,H,W,C) Rank 4 tensor; Batch_Size, Height, Width, Channel\n",
    "\n",
    "# 1nd Conv Layer \n",
    "c9 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "\n",
    "# Add some drop out for regularization\n",
    "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "\n",
    "# 2nd Conv Layer\n",
    "c9 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IoU metric\n",
    "def iou_metric(y_true, y_pred):\n",
    "  # Convert predictions to binary values using threshold of 0.5\n",
    "  y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "  \n",
    "  # Calculate intersection and union\n",
    "  intersection = tf.reduce_sum(y_true * y_pred)\n",
    "  union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "  \n",
    "  # Add small epsilon to avoid division by zero\n",
    "  iou = (intersection + 1e-7) / (union + 1e-7)\n",
    "  return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Layer\n",
    "outputs = tf.keras.layers.Conv2D(1,(1,1), activation='sigmoid')(c9)\n",
    "\n",
    "# Compile the model\n",
    "model = tf.keras.Model(inputs=[inputs],outputs=[outputs])\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy', iou_metric])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tensorboard\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Import time\n",
    "import datetime\n",
    "\n",
    "# Log file directory\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Tb callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of callbacks\n",
    "# Modelcheckpoint\n",
    "\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_nuclei.h5', verbose=1, save_best_only=True, save_weights_only=False)\n",
    "\n",
    "callbacks = [\n",
    "  # tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'), # If 2 iteration of val_loss is same then stop the further epochs\n",
    "  tensorboard_callback\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding our dataset\n",
    "\n",
    "[Data Link](https://www.kaggle.com/competitions/data-science-bowl-2018/data)\n",
    "\n",
    "The provided dataset contains `train` and `test`. The `test` data is go to go but, theirs an issue with the `training` data. In the `mask` folder their's masking for every nuclei. Instead of a single image of the segmented mask their is segmented image for every nuclei. \n",
    "\n",
    "Therefore, we need to perform preprocessing before we train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image preprocessing for Assignment\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TRAIN_PATH = './Nuclei_Dataset/stage1_train'\n",
    "TEST_PATH = './Nuclei_Dataset/stage1_test/'\n",
    "\n",
    "MASK_NAME = '/Final_mask_'\n",
    "\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1] # All folders for train\n",
    "test_ids = next(os.walk(TEST_PATH))[1] # All folders for test\n",
    "\n",
    "# RandomForestTraining\n",
    "# X_train = np.zeros((5, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), dtype=np.uint8) # Input\n",
    "# Y_train = np.zeros((5, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool_) # Output only one channel\n",
    "\n",
    "# U-Net Training\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), dtype=np.uint8) # Input\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool_) # Output only one channel\n",
    "\n",
    "img_count = 0\n",
    "\n",
    "# Resize and processing for training data\n",
    "for n, id_ in tqdm(enumerate(train_ids),total=len(train_ids)):\n",
    "  \n",
    "  path = TRAIN_PATH + '/' + id_\n",
    "  img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNEL] # Read all the 3 channels\n",
    "  img = resize(img,(IMG_HEIGHT,IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "\n",
    "  # print(img.shape)\n",
    "\n",
    "  mask_path = path + MASK_NAME + id_ + '/' + id_ + '.png'\n",
    "\n",
    "  # print(path + MASK_NAME + id_ + '/' + id_ + '.png')\n",
    "\n",
    "  X_train[n] = img\n",
    "\n",
    "  mask_ = imread(mask_path)\n",
    "  mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT,IMG_WIDTH), mode='constant', preserve_range=True), axis=-1)\n",
    "\n",
    "  Y_train[n] = mask_ \n",
    "\n",
    "  img_count += 1\n",
    "\n",
    "  # if img_count == 5:\n",
    "  #   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some random img\n",
    "\n",
    "for img, mask in zip(X_train, Y_train):\n",
    "  # Create a figure with two subplots side by side\n",
    "\n",
    "  print(mask.shape)\n",
    "  print(X_train.shape)\n",
    "  plt.figure(figsize=(10, 5))\n",
    "\n",
    "  # Convert BGR to RGB for matplotlib\n",
    "  img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "  # Display original image\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.imshow(img_rgb)  # Now using RGB image\n",
    "  plt.title('Original Image')\n",
    "  plt.axis('off')\n",
    "\n",
    "  # Display mask\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.imshow(np.squeeze(mask), cmap='gray')  # Mask remains unchanged as it's grayscale\n",
    "  plt.title('Mask')\n",
    "  plt.axis('off')\n",
    "\n",
    "  plt.show()\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above process using `NumPy` did not perform well. It will take a longer time to process the image. Therefore, we can plot these image as tensors using `tf` and then process.\n",
    "\n",
    "**Point to be Noted**\n",
    "\n",
    "First, research why `NumPy` are slower as compared to `Tensors`. Understand the under the hood processing of `NumPy`.\n",
    "\n",
    "Try to improve the performance of `NumPy` if possible, else use `tensors`. \n",
    "\n",
    "In the above task it's taking way too long to resize and add the images to the `initialized 4-D tensor` i.e. `X_train` with shape `(670,128,128,3)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize and processing for test data\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "\n",
    "print(\"Resizing test images\")\n",
    "\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + '/' + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNEL]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT,IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some random image after preprocessing\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imshow\n",
    "\n",
    "# Randomly select an image index\n",
    "image_x = random.randint(0, len(train_ids) - 1)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)  # Create a subplot with 1 row, 2 columns, position 1\n",
    "imshow(X_train[image_x])\n",
    "plt.title(\"Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the mask (converted to uint8 for proper visualization)\n",
    "plt.subplot(1, 2, 2)  # Create a subplot with 1 row, 2 columns, position 2\n",
    "imshow(np.squeeze(Y_train[image_x]))  # Convert boolean to uint8 (0 or 255)\n",
    "plt.title(\"Mask\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Fit\n",
    "result = model.fit(\n",
    "  X_train, \n",
    "\tY_train, \n",
    "\tvalidation_split=0.1,\n",
    "\tbatch_size=16,\n",
    "  epochs=50,\n",
    "  callbacks=callbacks\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the U-Net Model \n",
    "\n",
    "model.save('final_unet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics visualization U-Net\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.patheffects as path_effects\n",
    "\n",
    "def create_gradient_plot(ax, x, y1, y2, color1, color2, label1, label2):\n",
    "    \"\"\"Create a gradient-filled plot between two curves\"\"\"\n",
    "    ax.fill_between(x, y1, y2, color='gray', alpha=0.1)\n",
    "    line1 = ax.plot(x, y1, color=color1, label=label1, linewidth=2.5, marker='o', markersize=6)\n",
    "    line2 = ax.plot(x, y2, color=color2, label=label2, linewidth=2.5, marker='o', markersize=6)\n",
    "    \n",
    "    # Add glow effect to lines\n",
    "    for line in [line1[0], line2[0]]:\n",
    "        line.set_path_effects([\n",
    "            path_effects.Stroke(linewidth=4, foreground='black', alpha=0.3),\n",
    "            path_effects.Normal()\n",
    "        ])\n",
    "\n",
    "def style_ax(ax, title, xlabel, ylabel):\n",
    "    \"\"\"Apply consistent styling to axis\"\"\"\n",
    "    ax.set_title(title, fontsize=14, pad=20, color='white', \n",
    "                fontweight='bold', fontfamily='sans-serif')\n",
    "    ax.set_xlabel(xlabel, fontsize=12, color='white')\n",
    "    ax.set_ylabel(ylabel, fontsize=12, color='white')\n",
    "    ax.grid(True, linestyle='--', alpha=0.2)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.tick_params(colors='white')\n",
    "\n",
    "def plot_advanced_metrics(history):\n",
    "    \"\"\"\n",
    "    Create an advanced visualization of training metrics with modern styling\n",
    "    \"\"\"\n",
    "    # Set style\n",
    "    plt.style.use('dark_background')\n",
    "    \n",
    "    # Custom color palette\n",
    "    colors = {\n",
    "        'primary': '#00ff00',\n",
    "        'secondary': '#ff1493',\n",
    "        'accent': '#00ffff',\n",
    "        'background': '#1C1C1C',\n",
    "        'grid': '#333333'\n",
    "    }\n",
    "    \n",
    "    # Create figure with custom layout\n",
    "    fig = plt.figure(figsize=(20, 15), facecolor=colors['background'])\n",
    "    gs = GridSpec(3, 3, figure=fig, height_ratios=[2, 2, 1.5], hspace=0.4, wspace=0.3)\n",
    "    \n",
    "    # 1. Main Metrics Plots\n",
    "    metrics = ['loss', 'accuracy', 'iou_metric']\n",
    "    titles = ['Loss Curves', 'Accuracy Curves', 'IoU Score']\n",
    "    \n",
    "    for idx, metric in enumerate(metrics):\n",
    "        ax = fig.add_subplot(gs[0, idx])\n",
    "        ax.set_facecolor(colors['background'])\n",
    "        \n",
    "        create_gradient_plot(\n",
    "            ax,\n",
    "            range(1, len(history.history[metric]) + 1),\n",
    "            history.history[metric],\n",
    "            history.history[f'val_{metric}'],\n",
    "            colors['primary'],\n",
    "            colors['secondary'],\n",
    "            f'Training {metric.title()}',\n",
    "            f'Validation {metric.title()}'\n",
    "        )\n",
    "        \n",
    "        style_ax(ax, titles[idx], 'Epoch', metric.replace('_', ' ').title())\n",
    "        ax.legend(loc='upper right', facecolor=colors['background'], edgecolor='white')\n",
    "\n",
    "    # 2. Learning Curve Analysis\n",
    "    ax_learning = fig.add_subplot(gs[1, :2])\n",
    "    ax_learning.set_facecolor(colors['background'])\n",
    "    \n",
    "    # Calculate moving averages\n",
    "    window = 3\n",
    "    train_ma = pd.Series(history.history['loss']).rolling(window=window).mean()\n",
    "    val_ma = pd.Series(history.history['val_loss']).rolling(window=window).mean()\n",
    "    \n",
    "    create_gradient_plot(\n",
    "        ax_learning,\n",
    "        range(1, len(history.history['loss']) + 1),\n",
    "        train_ma,\n",
    "        val_ma,\n",
    "        colors['primary'],\n",
    "        colors['secondary'],\n",
    "        'Training Loss (MA)',\n",
    "        'Validation Loss (MA)'\n",
    "    )\n",
    "    \n",
    "    style_ax(ax_learning, 'Learning Curve Analysis', 'Epoch', 'Loss (Moving Average)')\n",
    "    ax_learning.legend(loc='upper right', facecolor=colors['background'], edgecolor='white')\n",
    "\n",
    "    # 3. Final Metrics Table with Modern Design\n",
    "    ax_metrics = fig.add_subplot(gs[1, 2])\n",
    "    ax_metrics.set_facecolor(colors['background'])\n",
    "    \n",
    "    final_metrics = {\n",
    "        'Training Loss': f\"{history.history['loss'][-1]:.4f}\",\n",
    "        'Validation Loss': f\"{history.history['val_loss'][-1]:.4f}\",\n",
    "        'Training Accuracy': f\"{history.history['accuracy'][-1]:.4f}\",\n",
    "        'Validation Accuracy': f\"{history.history['val_accuracy'][-1]:.4f}\",\n",
    "        'Training IoU': f\"{history.history['iou_metric'][-1]:.4f}\",\n",
    "        'Validation IoU': f\"{history.history['val_iou_metric'][-1]:.4f}\"\n",
    "    }\n",
    "    \n",
    "    # Create modern-looking table\n",
    "    cell_text = [[k, v] for k, v in final_metrics.items()]\n",
    "    table = ax_metrics.table(\n",
    "        cellText=cell_text,\n",
    "        cellLoc='center',\n",
    "        loc='center',\n",
    "        bbox=[0.1, 0.1, 0.8, 0.8]\n",
    "    )\n",
    "    \n",
    "    # Style table\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(11)\n",
    "    for k, cell in table._cells.items():\n",
    "        cell.set_edgecolor(colors['grid'])\n",
    "        cell.set_facecolor(colors['background'])\n",
    "        cell.set_text_props(color='white')\n",
    "        if k[1] == 1:  # Value cells\n",
    "            cell.set_text_props(weight='bold')\n",
    "    \n",
    "    ax_metrics.set_title('Final Metrics', pad=20, color='white', fontsize=14, fontweight='bold')\n",
    "    ax_metrics.axis('off')\n",
    "\n",
    "    # 4. Training Summary\n",
    "    ax_summary = fig.add_subplot(gs[2, :])\n",
    "    ax_summary.set_facecolor(colors['background'])\n",
    "    ax_summary.axis('off')\n",
    "    \n",
    "    summary_text = \"\"\"\n",
    "    Training Summary:\n",
    "    • Model showed {convergence} convergence over {epochs} epochs\n",
    "    • Final IoU score of {iou:.3f} indicates {performance} segmentation performance\n",
    "    • Validation loss {loss_trend} suggesting {overfitting}\n",
    "    \"\"\".format(\n",
    "        convergence = 'stable' if history.history['val_loss'][-1] < history.history['val_loss'][0] else 'unstable',\n",
    "        epochs = len(history.history['loss']),\n",
    "        iou = history.history['val_iou_metric'][-1],\n",
    "        performance = 'good' if history.history['val_iou_metric'][-1] > 0.7 else 'moderate' if history.history['val_iou_metric'][-1] > 0.5 else 'poor',\n",
    "        loss_trend = 'stabilized' if abs(history.history['val_loss'][-1] - history.history['val_loss'][-2]) < 0.01 else 'is still changing',\n",
    "        overfitting = 'minimal overfitting' if history.history['val_loss'][-1] < 1.2 * min(history.history['val_loss']) else 'potential overfitting'\n",
    "    )\n",
    "    \n",
    "    ax_summary.text(0.05, 0.6, summary_text, fontsize=12, color='white', \n",
    "                   fontfamily='monospace', linespacing=2)\n",
    "\n",
    "    # Main title with style\n",
    "    title = fig.suptitle('Segmentation Model Performance Analysis', \n",
    "                        fontsize=16, color='white', fontweight='bold', y=0.95)\n",
    "    title.set_path_effects([path_effects.withStroke(linewidth=2, foreground='gray')])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "plot_advanced_metrics(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter visualization 5 Layers of U-Net\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_filters(model, layer_name, max_filters=64):\n",
    "    \"\"\"\n",
    "    Visualize filters from a specific convolutional layer\n",
    "    \"\"\"\n",
    "    # Get the layer\n",
    "    layer = model.get_layer(layer_name)\n",
    "    weights, biases = layer.get_weights()\n",
    "    \n",
    "    # Normalize weights for better visualization\n",
    "    weights_min, weights_max = weights.min(), weights.max()\n",
    "    weights = (weights - weights_min) / (weights_max - weights_min)\n",
    "    \n",
    "    # Get number of filters and channels\n",
    "    n_filters, n_channels = weights.shape[3], weights.shape[2]\n",
    "    n_filters = min(n_filters, max_filters)  # Limit number of filters to display\n",
    "    \n",
    "    # Create figure with dark background\n",
    "    plt.style.use('dark_background')\n",
    "    fig = plt.figure(figsize=(20, 10), facecolor='#1C1C1C')\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    grid_size = int(np.ceil(np.sqrt(n_filters)))\n",
    "    \n",
    "    # Create ImageGrid\n",
    "    grid = ImageGrid(fig, 111,\n",
    "                    nrows_ncols=(grid_size, grid_size),\n",
    "                    axes_pad=0.3,\n",
    "                    share_all=True)\n",
    "    \n",
    "    # Plot filters\n",
    "    for idx in range(n_filters):\n",
    "        # Get the filter\n",
    "        filt = weights[:, :, :, idx]\n",
    "        \n",
    "        # Create RGB image by combining channels\n",
    "        if n_channels == 3:\n",
    "            img = filt\n",
    "        else:\n",
    "            img = np.mean(filt, axis=2)\n",
    "        \n",
    "        # Add filter to grid\n",
    "        im = grid[idx].imshow(img, cmap='viridis')\n",
    "        grid[idx].axis('off')\n",
    "        \n",
    "        # Add colorbar\n",
    "        if idx == n_filters - 1:\n",
    "            cbar = plt.colorbar(im, ax=grid.axes_all)\n",
    "            cbar.ax.set_ylabel('Filter Values', color='white')\n",
    "            cbar.ax.yaxis.set_tick_params(color='white')\n",
    "            plt.setp(plt.getp(cbar.ax.axes, 'yticklabels'), color='white')\n",
    "    \n",
    "    plt.suptitle(f'Filters in {layer_name}', color='white', fontsize=16, y=0.95)\n",
    "    plt.show()\n",
    "\n",
    "def plot_layer_activations(model, layer_name):\n",
    "    \"\"\"\n",
    "    Plot the distribution of weights and biases for a layer\n",
    "    \"\"\"\n",
    "    layer = model.get_layer(layer_name)\n",
    "    weights, biases = layer.get_weights()\n",
    "    \n",
    "    plt.style.use('dark_background')\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5), facecolor='#1C1C1C')\n",
    "    fig.patch.set_facecolor('#1C1C1C')\n",
    "    \n",
    "    # Plot weight distribution\n",
    "    sns.kdeplot(weights.ravel(), ax=ax1, color='#00ff00', fill=True, alpha=0.5)\n",
    "    ax1.set_title('Weight Distribution', color='white', pad=20)\n",
    "    ax1.set_xlabel('Weight Value', color='white')\n",
    "    ax1.set_ylabel('Density', color='white')\n",
    "    ax1.tick_params(colors='white')\n",
    "    \n",
    "    # Plot bias distribution\n",
    "    sns.kdeplot(biases.ravel(), ax=ax2, color='#ff1493', fill=True, alpha=0.5)\n",
    "    ax2.set_title('Bias Distribution', color='white', pad=20)\n",
    "    ax2.set_xlabel('Bias Value', color='white')\n",
    "    ax2.set_ylabel('Density', color='white')\n",
    "    ax2.tick_params(colors='white')\n",
    "    \n",
    "    plt.suptitle(f'Weight and Bias Distributions for {layer_name}', color='white', fontsize=16, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_model_weights():\n",
    "    \"\"\"\n",
    "    Visualize weights for multiple layers of the model\n",
    "    \"\"\"\n",
    "    # List of conv layers to visualize\n",
    "    conv_layers = [layer.name for layer in model.layers if 'conv2d' in layer.name][:6]  # First 6 conv layers\n",
    "    \n",
    "    print(\"Visualizing filters and weights for key layers...\")\n",
    "    \n",
    "    for layer_name in conv_layers:\n",
    "        print(f\"\\nAnalyzing {layer_name}...\")\n",
    "        \n",
    "        # Visualize filters\n",
    "        visualize_filters(model, layer_name)\n",
    "        \n",
    "        # Plot weight and bias distributions\n",
    "        plot_layer_activations(model, layer_name)\n",
    "        \n",
    "        # Add separator\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# Call the visualization function\n",
    "visualize_model_weights()\n",
    "\n",
    "# Additional analysis of model architecture\n",
    "def plot_layer_sizes():\n",
    "    \"\"\"\n",
    "    Plot the number of parameters per layer\n",
    "    \"\"\"\n",
    "    plt.style.use('dark_background')\n",
    "    fig = plt.figure(figsize=(15, 8), facecolor='#1C1C1C')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_facecolor('#1C1C1C')\n",
    "    \n",
    "    # Get layer names and parameters\n",
    "    layer_names = [layer.name for layer in model.layers if len(layer.get_weights()) > 0]\n",
    "    params = [np.sum([w.size for w in layer.get_weights()]) for layer in model.layers if len(layer.get_weights()) > 0]\n",
    "    \n",
    "    # Create bar plot\n",
    "    bars = ax.bar(range(len(layer_names)), params, color='#00ff00', alpha=0.7)\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_xticks(range(len(layer_names)))\n",
    "    ax.set_xticklabels(layer_names, rotation=45, ha='right')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel('Number of Parameters (log scale)', color='white')\n",
    "    ax.set_title('Model Layer Sizes', color='white', pad=20)\n",
    "    ax.tick_params(colors='white')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height):,}',\n",
    "                ha='center', va='bottom', color='white', rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot layer sizes\n",
    "plot_layer_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Test with Random Image\n",
    "\n",
    "idx = random.randint(0, len(X_train)-1)\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(\n",
    "    'final_unet_model.h5',\n",
    "    custom_objects={'iou_metric': iou_metric}\n",
    ")\n",
    "\n",
    "preds_train = loaded_model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = loaded_model.predict(X_train[:int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = loaded_model.predict(X_train, verbose=1)\n",
    "\n",
    "# Convert predictions to binary masks\n",
    "prest_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "prest_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "prest_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Random training samples\n",
    "ix = random.randint(0, len(prest_test_t))\n",
    "\n",
    "# Display with matplotlib\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(X_train[ix])\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.squeeze(Y_train[ix]), cmap='gray')\n",
    "plt.title('True Mask')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(np.squeeze(prest_test_t[ix]), cmap='gray')\n",
    "plt.title('Predicted Mask')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Display with OpenCV (corrected version)\n",
    "# Scale the prediction to proper range for visualization\n",
    "prediction = np.squeeze(prest_test_t[ix])  # Remove extra dimensions\n",
    "prediction = (prediction * 255).astype(np.uint8)  # Scale to 0-255 range\n",
    "\n",
    "# Create a window\n",
    "cv.namedWindow(\"Prediction\", cv.WINDOW_NORMAL)\n",
    "cv.resizeWindow(\"Prediction\", 512, 512)  # Set window size\n",
    "\n",
    "# Show the image\n",
    "cv.imshow(\"Prediction\", prediction)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "# For validation samples\n",
    "split_idx = int(X_train.shape[0]*0.9)\n",
    "X_val = X_train[split_idx:]\n",
    "Y_val = Y_train[split_idx:]\n",
    "\n",
    "# Random validation samples\n",
    "ix = random.randint(0, len(X_val) - 1)\n",
    "\n",
    "# Display validation images\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_val[ix])\n",
    "plt.title('Validation Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.squeeze(Y_val[ix]), cmap='gray')\n",
    "plt.title('Validation Mask')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Random index selected: {ix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net Prediction Testing Data 5 Images \n",
    "\n",
    "def create_unet_train_visualization(model, X_train, Y_train, n_samples=5, figsize=(15, 10)):\n",
    "    \"\"\"\n",
    "    Create an attractive visualization of U-Net segmentation predictions on training data\n",
    "    with black and white ground truth masks\n",
    "    \"\"\"\n",
    "    # Style constants\n",
    "    BACKGROUND_COLOR = '#0f172a'  # Dark blue background\n",
    "    TEXT_COLOR = '#e2e8f0'       # Light gray text\n",
    "    ACCENT_COLOR = '#38bdf8'     # Light blue accent\n",
    "    \n",
    "    # Set style\n",
    "    plt.style.use('dark_background')\n",
    "    \n",
    "    # Select random indices\n",
    "    indices = np.random.choice(len(X_train), n_samples, replace=False)\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=figsize, facecolor=BACKGROUND_COLOR)\n",
    "    \n",
    "    # Add title\n",
    "    fig.suptitle('U-Net Segmentation Analysis (Training Data)',\n",
    "                 color=TEXT_COLOR,\n",
    "                 fontsize=24,\n",
    "                 fontweight='bold',\n",
    "                 y=0.98)\n",
    "    \n",
    "    # Get predictions\n",
    "    raw_predictions = model.predict(X_train[indices], verbose=0)\n",
    "    predictions = (raw_predictions > 0.5).astype(np.uint8)\n",
    "    \n",
    "    # Create layout\n",
    "    for idx in range(n_samples):\n",
    "        # Calculate positions for images\n",
    "        y_pos = 0.78 - (idx * 0.145)\n",
    "        \n",
    "        # Original image - left\n",
    "        ax1 = fig.add_axes([0.05, y_pos, 0.25, 0.12])\n",
    "        ax1.imshow(X_train[indices[idx]])\n",
    "        ax1.axis('off')\n",
    "        ax1.set_title(\"Original\", fontsize=10, color=TEXT_COLOR, pad=8)\n",
    "        \n",
    "        # Add case number\n",
    "        ax1.text(-0.12, 0.5, f'#{idx+1}',\n",
    "                transform=ax1.transAxes,\n",
    "                color=ACCENT_COLOR,\n",
    "                fontsize=12,\n",
    "                fontweight='bold',\n",
    "                ha='right',\n",
    "                va='center')\n",
    "        \n",
    "        # Ground truth mask - middle (black and white)\n",
    "        ax2 = fig.add_axes([0.35, y_pos, 0.25, 0.12])\n",
    "        ax2.imshow(np.squeeze(Y_train[indices[idx]]), cmap='binary', vmin=0, vmax=1)\n",
    "        ax2.axis('off')\n",
    "        ax2.set_title(\"Ground Truth\", fontsize=10, color=TEXT_COLOR, pad=8)\n",
    "        \n",
    "        # Prediction - right\n",
    "        ax3 = fig.add_axes([0.65, y_pos, 0.25, 0.12])\n",
    "        pred_img = np.squeeze(predictions[idx])\n",
    "        im = ax3.imshow(pred_img, cmap='viridis')\n",
    "        ax3.axis('off')\n",
    "        ax3.set_title(\"Prediction\", fontsize=10, color=TEXT_COLOR, pad=8)\n",
    "        \n",
    "        # Calculate IoU score\n",
    "        intersection = np.logical_and(Y_train[indices[idx]], predictions[idx])\n",
    "        union = np.logical_or(Y_train[indices[idx]], predictions[idx])\n",
    "        iou_score = np.sum(intersection) / np.sum(union)\n",
    "        \n",
    "        # Add IoU score box\n",
    "        ax3.text(1.12, 0.5,\n",
    "                f'IoU\\n{iou_score:.2f}',\n",
    "                transform=ax3.transAxes,\n",
    "                color=TEXT_COLOR,\n",
    "                fontsize=9,\n",
    "                ha='left',\n",
    "                va='center',\n",
    "                bbox=dict(facecolor=BACKGROUND_COLOR, \n",
    "                         alpha=0.8,\n",
    "                         edgecolor=ACCENT_COLOR,\n",
    "                         boxstyle='round,pad=0.4'))\n",
    "        \n",
    "        # Add connecting lines\n",
    "        con_line1 = plt.Line2D([0.30, 0.35], [y_pos + 0.06, y_pos + 0.06],\n",
    "                              color=ACCENT_COLOR,\n",
    "                              alpha=0.3,\n",
    "                              transform=fig.transFigure,\n",
    "                              linestyle='--')\n",
    "        con_line2 = plt.Line2D([0.60, 0.65], [y_pos + 0.06, y_pos + 0.06],\n",
    "                              color=ACCENT_COLOR,\n",
    "                              alpha=0.3,\n",
    "                              transform=fig.transFigure,\n",
    "                              linestyle='--')\n",
    "        fig.add_artist(con_line1)\n",
    "        fig.add_artist(con_line2)\n",
    "    \n",
    "    # Add colorbar (only for prediction confidence)\n",
    "    cax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    cbar.set_label('Prediction Confidence',\n",
    "                   color=TEXT_COLOR,\n",
    "                   fontsize=9,\n",
    "                   labelpad=10)\n",
    "    cbar.ax.tick_params(colors=TEXT_COLOR, labelsize=8)\n",
    "    \n",
    "    # Add footer with model info\n",
    "    footer_text = (f'U-Net Architecture | Input Shape: {X_train.shape[1:]} | '\n",
    "                  f'Generated: {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")}')\n",
    "    plt.figtext(0.5, 0.02,\n",
    "                footer_text,\n",
    "                color=TEXT_COLOR,\n",
    "                fontsize=8,\n",
    "                ha='center',\n",
    "                alpha=0.7)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(top=0.92, bottom=0.01, right=0.90, left=0.05)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "# Create and display visualization\n",
    "fig = create_unet_train_visualization(model, X_train, Y_train)\n",
    "\n",
    "# Optionally save the visualization\n",
    "# plt.savefig('unet_train_predictions.png',\n",
    "#             facecolor='#0f172a',\n",
    "#             bbox_inches='tight',\n",
    "#             dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net Time Per Image Prediction\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def calculate_prediction_time(model, X_test, num_runs=3):\n",
    "    \"\"\"\n",
    "    Calculate average prediction time per image using X_test data\n",
    "    Args:\n",
    "        model: Trained U-Net model\n",
    "        X_test: Test dataset\n",
    "        num_runs: Number of times to run predictions for averaging\n",
    "    Returns:\n",
    "        avg_time_per_image: Average time per image in milliseconds\n",
    "        std_time_per_image: Standard deviation of prediction time\n",
    "        total_time: Total time taken for all predictions\n",
    "    \"\"\"\n",
    "    print(f\"\\nCalculating prediction times over {num_runs} runs...\")\n",
    "    all_times = []\n",
    "    \n",
    "    for run in range(num_runs):\n",
    "        times = []\n",
    "        with tqdm(total=len(X_test), desc=f\"Run {run+1}/{num_runs}\", ncols=100) as pbar:\n",
    "            for i in range(len(X_test)):\n",
    "                # Get single image\n",
    "                img = X_test[i:i+1]\n",
    "                \n",
    "                # Time prediction\n",
    "                start_time = time.time()\n",
    "                _ = model.predict(img, verbose=0)\n",
    "                end_time = time.time()\n",
    "                \n",
    "                # Store time in milliseconds\n",
    "                pred_time = (end_time - start_time) * 1000\n",
    "                times.append(pred_time)\n",
    "                pbar.update(1)\n",
    "        \n",
    "        all_times.extend(times)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    avg_time = np.mean(all_times)\n",
    "    std_time = np.std(all_times)\n",
    "    total_time = np.sum(all_times)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nPrediction Time Analysis:\")\n",
    "    print(f\"Average time per image: {avg_time:.2f} ms\")\n",
    "    print(f\"Standard deviation: {std_time:.2f} ms\")\n",
    "    print(f\"Total time for {len(X_test)} images: {total_time/1000:.2f} seconds\")\n",
    "    \n",
    "    # Set style for better visualization\n",
    "    plt.style.use('dark_background')\n",
    "    sns.set_palette(\"husl\")\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    fig.suptitle('U-Net Prediction Time Analysis', fontsize=16, y=1.05)\n",
    "    \n",
    "    # 1. Histogram with KDE\n",
    "    sns.histplot(data=all_times, bins=30, ax=ax1, color='#00FF9F', alpha=0.6, kde=True)\n",
    "    ax1.axvline(avg_time, color='#FF69B4', linestyle='--', \n",
    "                label=f'Mean: {avg_time:.2f}ms')\n",
    "    ax1.axvline(np.median(all_times), color='#4169E1', linestyle='--', \n",
    "                label=f'Median: {np.median(all_times):.2f}ms')\n",
    "    ax1.set_title('Distribution of Prediction Times')\n",
    "    ax1.set_xlabel('Time (ms)')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # 2. Box plot with individual points\n",
    "    sns.boxplot(y=all_times, ax=ax2, color='#00FF9F', width=0.3)\n",
    "    sns.stripplot(y=all_times, ax=ax2, color='#FF69B4', alpha=0.4, size=4)\n",
    "    ax2.set_title('Prediction Time Distribution')\n",
    "    ax2.set_ylabel('Time (ms)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add text box with statistics\n",
    "    stats_text = (f'Statistics:\\n'\n",
    "                 f'Mean: {avg_time:.2f}ms\\n'\n",
    "                 f'Std Dev: {std_time:.2f}ms\\n'\n",
    "                 f'Min: {np.min(all_times):.2f}ms\\n'\n",
    "                 f'Max: {np.max(all_times):.2f}ms')\n",
    "    ax2.text(1.05, 0.95, stats_text, transform=ax2.transAxes, \n",
    "             bbox=dict(facecolor='#1C1C1C', alpha=0.8, edgecolor='#4A4A4A'),\n",
    "             fontsize=10, color='white')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return avg_time, std_time, total_time\n",
    "\n",
    "# Calculate prediction times\n",
    "avg_time, std_time, total_time = calculate_prediction_time(model, X_test)\n",
    "\n",
    "# Save results to file\n",
    "with open('prediction_time_results.txt', 'w') as f:\n",
    "    f.write(\"U-Net Model Prediction Time Analysis\\n\")\n",
    "    f.write(\"==================================\\n\\n\")\n",
    "    f.write(f\"Number of test images: {len(X_test)}\\n\")\n",
    "    f.write(f\"Average prediction time per image: {avg_time:.2f} ms\\n\")\n",
    "    f.write(f\"Standard deviation: {std_time:.2f} ms\\n\")\n",
    "    f.write(f\"Total prediction time: {total_time/1000:.2f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net Visualize Each Layer Activation\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_layer_visualization_model(model, layer_name):\n",
    "    \"\"\"\n",
    "    Create a model that outputs the activations of a specific layer\n",
    "    \"\"\"\n",
    "    return Model(\n",
    "        inputs=model.input,\n",
    "        outputs=model.get_layer(layer_name).output\n",
    "    )\n",
    "\n",
    "def visualize_layer_activations(activations, layer_name, num_cols=8):\n",
    "    \"\"\"\n",
    "    Visualize the activations of a layer in a grid\n",
    "    \"\"\"\n",
    "    # Get the number of filters\n",
    "    num_filters = activations.shape[-1]\n",
    "    \n",
    "    # Calculate number of rows needed\n",
    "    num_rows = (num_filters + num_cols - 1) // num_cols\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(num_cols * 2, num_rows * 2))\n",
    "    plt.suptitle(f'Layer: {layer_name} - {num_filters} filters', fontsize=16)\n",
    "    \n",
    "    # Plot each filter's activation\n",
    "    for i in range(num_filters):\n",
    "        plt.subplot(num_rows, num_cols, i + 1)\n",
    "        \n",
    "        # Get the activation for this filter\n",
    "        activation = activations[0, :, :, i]\n",
    "        \n",
    "        # Normalize the activation for better visualization\n",
    "        activation = (activation - activation.min()) / (activation.max() - activation.min() + 1e-9)\n",
    "        \n",
    "        plt.imshow(activation, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Filter {i+1}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_layer_names(model):\n",
    "    \"\"\"\n",
    "    Get names of all convolutional and transpose convolutional layers\n",
    "    \"\"\"\n",
    "    layer_names = []\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.Conv2DTranspose)):\n",
    "            layer_names.append(layer.name)\n",
    "    return layer_names\n",
    "\n",
    "def visualize_all_layer_activations(model, input_image):\n",
    "    \"\"\"\n",
    "    Visualize activations for all convolutional layers in the model\n",
    "    \"\"\"\n",
    "    # Get all conv layer names\n",
    "    layer_names = get_layer_names(model)\n",
    "    \n",
    "    print(f\"Found {len(layer_names)} convolutional layers\")\n",
    "    \n",
    "    # Create visualization for each layer\n",
    "    for layer_name in layer_names:\n",
    "        print(f\"\\nVisualizing layer: {layer_name}\")\n",
    "        \n",
    "        # Create intermediate model\n",
    "        layer_model = create_layer_visualization_model(model, layer_name)\n",
    "        \n",
    "        # Get activations\n",
    "        activations = layer_model.predict(np.expand_dims(input_image, axis=0))\n",
    "        \n",
    "        # Visualize activations\n",
    "        visualize_layer_activations(activations, layer_name)\n",
    "\n",
    "def display_final_comparison(model, image, actual_mask):\n",
    "    \"\"\"\n",
    "    Display the original image, actual mask, and predicted mask side by side\n",
    "    \"\"\"\n",
    "    # Get prediction\n",
    "    pred_mask = model.predict(np.expand_dims(image, axis=0))\n",
    "    pred_mask = (pred_mask > 0.5).astype(np.uint8)\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot original image\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot actual mask\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(actual_mask.squeeze(), cmap='gray')\n",
    "    plt.title('Actual Mask')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot predicted mask\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(pred_mask.squeeze(), cmap='gray')\n",
    "    plt.title('Predicted Mask')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Calculate IoU score\n",
    "    intersection = np.logical_and(actual_mask, pred_mask.squeeze())\n",
    "    union = np.logical_or(actual_mask, pred_mask.squeeze())\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    \n",
    "    plt.suptitle(f'Segmentation Results (IoU Score: {iou_score:.3f})', fontsize=16, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = tf.keras.models.load_model(\n",
    "    'final_unet_model.h5',\n",
    "    custom_objects={'iou_metric': iou_metric}\n",
    ")\n",
    "\n",
    "# Select a random test image\n",
    "random_idx = np.random.randint(0, len(X_test))\n",
    "test_image = X_train[random_idx]\n",
    "actual_mask = Y_train[random_idx]\n",
    "\n",
    "# Create figure to show original image\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(test_image)\n",
    "plt.title('Original Test Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Visualize activations for all layers\n",
    "visualize_all_layer_activations(loaded_model, test_image)\n",
    "display_final_comparison(loaded_model, test_image, actual_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net Grad-CAM with Proper Color \n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def compute_gradcam(model, img_array, last_conv_layer_name):\n",
    "    \"\"\"\n",
    "    Compute Grad-CAM for a given image and model\n",
    "    \"\"\"\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=[model.input], \n",
    "        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    conv_outputs = conv_outputs.numpy()[0]\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        conv_outputs[:, :, i] *= pooled_grads[i].numpy()\n",
    "\n",
    "    heatmap = np.mean(conv_outputs, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "def apply_heatmap(original_image, heatmap):\n",
    "    \"\"\"\n",
    "    Apply heatmap overlay on original image\n",
    "    \"\"\"\n",
    "    # Use cool-warm colormap for better visualization\n",
    "    colormap = plt.get_cmap('coolwarm')\n",
    "    heatmap_colored = (colormap(heatmap) * 255).astype(np.uint8)\n",
    "    \n",
    "    # Convert to BGR for OpenCV\n",
    "    heatmap_bgr = cv2.cvtColor(heatmap_colored, cv2.COLOR_RGBA2BGR)\n",
    "    \n",
    "    # Resize and overlay\n",
    "    heatmap_resized = cv2.resize(heatmap_bgr, (original_image.shape[1], original_image.shape[0]))\n",
    "    superimposed = cv2.addWeighted(original_image, 0.6, heatmap_resized, 0.4, 0)\n",
    "    \n",
    "    return superimposed, heatmap_colored[:,:,:3]\n",
    "\n",
    "def visualize_gradcam(model, X_test, selected_indices, last_conv_layer_name='conv2d_18'):\n",
    "    \"\"\"\n",
    "    Create comprehensive Grad-CAM visualization\n",
    "    \"\"\"\n",
    "    # Style constants\n",
    "    BACKGROUND_COLOR = '#0A192F'  # Dark blue background\n",
    "    TEXT_COLOR = '#8892B0'        # Light blue-gray text\n",
    "    TITLE_COLOR = '#64FFDA'       # Cyan titles\n",
    "    \n",
    "    # Set style\n",
    "    plt.style.use('dark_background')\n",
    "    \n",
    "    # Create figure\n",
    "    num_samples = len(selected_indices)\n",
    "    fig = plt.figure(figsize=(20, num_samples * 4))\n",
    "    fig.patch.set_facecolor(BACKGROUND_COLOR)\n",
    "    \n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        img = X_test[idx]\n",
    "        img_array = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        # Get prediction and prepare mask\n",
    "        pred_mask = loaded_model.predict(img_array, verbose=0)\n",
    "        binary_mask = (pred_mask > 0.5).astype(np.uint8)\n",
    "        display_mask = np.squeeze(binary_mask)\n",
    "        display_mask = (display_mask * 255).astype(np.uint8)\n",
    "        \n",
    "        # Compute Grad-CAM\n",
    "        heatmap = compute_gradcam(loaded_model, img_array, last_conv_layer_name)\n",
    "        superimposed, colored_heatmap = apply_heatmap(img, heatmap)\n",
    "        \n",
    "        # Plot results in a row\n",
    "        # Original Image\n",
    "        ax1 = plt.subplot(num_samples, 4, i * 4 + 1)\n",
    "        ax1.imshow(img)\n",
    "        ax1.set_title('Original Image', color=TITLE_COLOR, fontsize=12, pad=10)\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        # Add case number\n",
    "        ax1.text(-0.1, 0.5, f'Case #{i+1}',\n",
    "                transform=ax1.transAxes,\n",
    "                color=TITLE_COLOR,\n",
    "                fontsize=10,\n",
    "                fontweight='bold',\n",
    "                ha='right',\n",
    "                va='center')\n",
    "        \n",
    "        # Attention Heatmap\n",
    "        ax2 = plt.subplot(num_samples, 4, i * 4 + 2)\n",
    "        im = ax2.imshow(colored_heatmap)\n",
    "        ax2.set_title('Attention Heatmap', color=TITLE_COLOR, fontsize=12, pad=10)\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        # Add colorbar to first heatmap only\n",
    "        if i == 0:\n",
    "            cax = plt.axes([0.47, 0.95, 0.1, 0.01])\n",
    "            cbar = plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "            cbar.set_label('Attention Intensity', color=TEXT_COLOR)\n",
    "            cbar.ax.xaxis.set_tick_params(color=TEXT_COLOR)\n",
    "            plt.setp(plt.getp(cbar.ax.axes, 'xticklabels'), color=TEXT_COLOR)\n",
    "        \n",
    "        # Heatmap Overlay\n",
    "        ax3 = plt.subplot(num_samples, 4, i * 4 + 3)\n",
    "        ax3.imshow(superimposed)\n",
    "        ax3.set_title('Heatmap Overlay', color=TITLE_COLOR, fontsize=12, pad=10)\n",
    "        ax3.axis('off')\n",
    "        \n",
    "        # Binary Prediction\n",
    "        ax4 = plt.subplot(num_samples, 4, i * 4 + 4)\n",
    "        ax4.imshow(display_mask, cmap='gray')\n",
    "        ax4.set_title('Binary Prediction', color=TITLE_COLOR, fontsize=12, pad=10)\n",
    "        ax4.axis('off')\n",
    "        \n",
    "        # Add connecting lines\n",
    "        con_line1 = plt.Line2D([0.305, 0.315], [0.75 - i * 0.25, 0.75 - i * 0.25],\n",
    "                              color=TITLE_COLOR,\n",
    "                              alpha=0.3,\n",
    "                              transform=fig.transFigure,\n",
    "                              linestyle='--')\n",
    "        con_line2 = plt.Line2D([0.575, 0.585], [0.75 - i * 0.25, 0.75 - i * 0.25],\n",
    "                              color=TITLE_COLOR,\n",
    "                              alpha=0.3,\n",
    "                              transform=fig.transFigure,\n",
    "                              linestyle='--')\n",
    "        fig.add_artist(con_line1)\n",
    "        fig.add_artist(con_line2)\n",
    "\n",
    "    # Main title\n",
    "    plt.suptitle('Nuclear Segmentation: Model Attention Analysis', \n",
    "                 color=TITLE_COLOR, \n",
    "                 fontsize=16, \n",
    "                 y=0.98)\n",
    "\n",
    "    # Add interpretation guide\n",
    "    guide_text = (\n",
    "        \"Model Attention Analysis Guide:\\n\"\n",
    "        \"• Red/Warm Colors: High attention - model focuses strongly on these regions\\n\"\n",
    "        \"• Blue/Cool Colors: Low attention - model considers these areas less important\\n\"\n",
    "        f\"\\nGenerated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}\"\n",
    "    )\n",
    "    plt.figtext(0.5, 0.02,\n",
    "                guide_text,\n",
    "                color=TEXT_COLOR,\n",
    "                fontsize=8,\n",
    "                ha='center',\n",
    "                alpha=0.7)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.04, 1, 0.96])\n",
    "    return fig\n",
    "\n",
    "# Usage example:\n",
    "selected_indices = [0, 1, 2]  # Choose which images to visualize\n",
    "fig = visualize_gradcam(loaded_model, X_test, selected_indices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net LRP Model Explanation\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "class LRPExplainer:\n",
    "    def __init__(self, model, epsilon=1e-7):\n",
    "        self.model = model\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def get_layer_outputs(self, image):\n",
    "        \"\"\"Get outputs of all layers for an input image\"\"\"\n",
    "        layer_outputs = []\n",
    "        layer_names = []\n",
    "        \n",
    "        layer_model = Model(\n",
    "            inputs=self.model.input,\n",
    "            outputs=[layer.output for layer in self.model.layers]\n",
    "        )\n",
    "        \n",
    "        activations = layer_model.predict(np.expand_dims(image, axis=0))\n",
    "        return activations, [layer.name for layer in self.model.layers]\n",
    "    \n",
    "    def compute_lrp(self, image, target_layer_idx=-1):\n",
    "        \"\"\"Compute LRP relevance scores\"\"\"\n",
    "        activations, layer_names = self.get_layer_outputs(image)\n",
    "        relevance = activations[target_layer_idx][0]\n",
    "        \n",
    "        if len(relevance.shape) == 3 and relevance.shape[-1] == 1:\n",
    "            relevance = relevance[..., 0]\n",
    "            \n",
    "        relevance = (relevance - relevance.min()) / (relevance.max() - relevance.min() + self.epsilon)\n",
    "        return relevance\n",
    "    \n",
    "    def generate_report(self, relevance, binary_mask):\n",
    "        \"\"\"Generate analysis report\"\"\"\n",
    "        report = {\n",
    "            'max_relevance': float(relevance.max()),\n",
    "            'mean_relevance': float(relevance.mean()),\n",
    "            'std_relevance': float(relevance.std()),\n",
    "            'positive_regions': int(np.sum(relevance > relevance.mean())),\n",
    "            'total_regions': relevance.size,\n",
    "            'detected_objects': int(np.sum(binary_mask > 0)),\n",
    "            'confidence_score': float(np.mean(relevance[binary_mask > 0]) if np.sum(binary_mask > 0) > 0 else 0)\n",
    "        }\n",
    "        return report\n",
    "    \n",
    "    def visualize_explanation(self, image, true_mask=None, idx=0):\n",
    "        \"\"\"Generate and visualize LRP explanation with report\"\"\"\n",
    "        plt.style.use('dark_background')\n",
    "        BACKGROUND_COLOR = '#0A192F'\n",
    "        TEXT_COLOR = '#8892B0'\n",
    "        TITLE_COLOR = '#64FFDA'\n",
    "        \n",
    "        # Create figure with space for report\n",
    "        fig = plt.figure(figsize=(20, 6))\n",
    "        fig.patch.set_facecolor(BACKGROUND_COLOR)\n",
    "        \n",
    "        # Ensure image is in correct format\n",
    "        if len(image.shape) == 3:\n",
    "            display_image = image[..., 0]\n",
    "        else:\n",
    "            display_image = image\n",
    "            \n",
    "        # Original Image\n",
    "        ax1 = plt.subplot(151)\n",
    "        ax1.imshow(display_image, cmap='gray')\n",
    "        ax1.set_title('Original Image', color=TITLE_COLOR)\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        # Model Prediction\n",
    "        pred_mask = self.model.predict(np.expand_dims(image, axis=0), verbose=0)[0]\n",
    "        binary_mask = (pred_mask > 0.5).astype(np.uint8)\n",
    "        \n",
    "        ax2 = plt.subplot(152)\n",
    "        ax2.imshow(binary_mask[..., 0], cmap='gray')\n",
    "        ax2.set_title('Model Prediction', color=TITLE_COLOR)\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        # True Mask\n",
    "        if true_mask is not None:\n",
    "            ax3 = plt.subplot(153)\n",
    "            if len(true_mask.shape) == 3:\n",
    "                true_mask = true_mask[..., 0]\n",
    "            ax3.imshow(true_mask, cmap='gray')\n",
    "            ax3.set_title('True Mask', color=TITLE_COLOR)\n",
    "            ax3.axis('off')\n",
    "        \n",
    "        # Compute LRP relevance\n",
    "        relevance = self.compute_lrp(image)\n",
    "        \n",
    "        # Generate report\n",
    "        report = self.generate_report(relevance, binary_mask[..., 0])\n",
    "        \n",
    "        # LRP Heatmap\n",
    "        ax4 = plt.subplot(154)\n",
    "        im = ax4.imshow(relevance, cmap='coolwarm')\n",
    "        ax4.set_title('LRP Relevance', color=TITLE_COLOR)\n",
    "        ax4.axis('off')\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im)\n",
    "        cbar.set_label('Relevance Score', color=TEXT_COLOR)\n",
    "        cbar.ax.yaxis.set_tick_params(color=TEXT_COLOR)\n",
    "        plt.setp(plt.getp(cbar.ax.axes, 'yticklabels'), color=TEXT_COLOR)\n",
    "        \n",
    "        # Create overlay\n",
    "        display_image_3ch = cv2.cvtColor((display_image * 255).astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
    "        relevance_3ch = cv2.applyColorMap((relevance * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "        overlay = cv2.addWeighted(display_image_3ch, 0.6, relevance_3ch, 0.4, 0)\n",
    "        \n",
    "        ax5 = plt.subplot(155)\n",
    "        ax5.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "        ax5.set_title('Relevance Overlay', color=TITLE_COLOR)\n",
    "        ax5.axis('off')\n",
    "        \n",
    "        # Add report text\n",
    "        report_text = (\n",
    "            f\"LRP Analysis Report\\n\"\n",
    "            f\"─────────────────\\n\"\n",
    "            f\"Max Relevance: {report['max_relevance']:.3f}\\n\"\n",
    "            f\"Mean Relevance: {report['mean_relevance']:.3f}\\n\"\n",
    "            f\"Std Relevance: {report['std_relevance']:.3f}\\n\"\n",
    "            f\"Positive Regions: {report['positive_regions']}\\n\"\n",
    "            f\"Detected Objects: {report['detected_objects']}\\n\"\n",
    "            f\"Confidence Score: {report['confidence_score']:.3f}\\n\"\n",
    "            f\"\\nGenerated: {datetime.now().strftime('%Y-%m-%d %H:%M')}\"\n",
    "        )\n",
    "        \n",
    "        # Add report box\n",
    "        plt.figtext(0.5, -0.15, report_text,\n",
    "                   ha='center',\n",
    "                   va='top',\n",
    "                   color=TEXT_COLOR,\n",
    "                   fontsize=10,\n",
    "                   bbox=dict(facecolor=BACKGROUND_COLOR,\n",
    "                           edgecolor=TITLE_COLOR,\n",
    "                           alpha=0.8,\n",
    "                           boxstyle='round,pad=1'))\n",
    "        \n",
    "        plt.suptitle('U-Net Segmentation: Layer-wise Relevance Propagation', \n",
    "                    color=TITLE_COLOR, \n",
    "                    fontsize=16, \n",
    "                    y=1.05)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save with extra space for report\n",
    "        plt.savefig(f'lrp_explanation_{idx}.png', \n",
    "                    bbox_inches='tight', \n",
    "                    facecolor=fig.get_facecolor(), \n",
    "                    edgecolor='none', \n",
    "                    dpi=300,\n",
    "                    pad_inches=1.5)  # Extra padding for report\n",
    "        plt.close()\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        return relevance, report\n",
    "\n",
    "def explain_image(model, image, true_mask=None, idx=0):\n",
    "    \"\"\"Generate LRP explanation for a single image\"\"\"\n",
    "    explainer = LRPExplainer(model)\n",
    "    relevance, report = explainer.visualize_explanation(image, true_mask, idx)\n",
    "    return relevance, report\n",
    "\n",
    "def explain_multiple_images(model, X_train, Y_train, indices):\n",
    "    \"\"\"Generate LRP explanations for multiple images\"\"\"\n",
    "    reports = []\n",
    "    for idx in indices:\n",
    "        print(f\"Processing image {idx}\")\n",
    "        image = X_train[idx]\n",
    "        true_mask = Y_train[idx]\n",
    "        relevance, report = explain_image(model, image, true_mask, idx)\n",
    "        reports.append(report)\n",
    "    return reports\n",
    "\n",
    "# Example usage:\n",
    "# For single image\n",
    "idx = 0\n",
    "image = X_train[idx]\n",
    "true_mask = Y_train[idx]\n",
    "relevance, report = explain_image(loaded_model, image, true_mask, idx)\n",
    "print(\"\\nAnalysis Report for Single Image:\")\n",
    "for key, value in report.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# For multiple images\n",
    "selected_indices = [0, 1, 2]  # Choose images to explain\n",
    "reports = explain_multiple_images(loaded_model, X_train, Y_train, selected_indices)\n",
    "\n",
    "# Print summary of all reports\n",
    "print(\"\\nSummary of All Reports:\")\n",
    "for idx, report in enumerate(reports):\n",
    "    print(f\"\\nImage {selected_indices[idx]}:\")\n",
    "    for key, value in report.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Approach VGG x Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG for Feature Extraction and RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes for VGG16\n",
    "\n",
    "For the feature extraction we've use the Img Resolution of (256,256) because if we start with (128,128) only one layer of the VGG16 will be used to extract feature i.e. less feature extracted. \n",
    "\n",
    "Another approach is to resize the Input Size (Resources Trade Off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(256,256,IMG_CHANNEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the layers non trainable as are using it for feature extraction\n",
    "for layer in VGG_model.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Model(VGG_model.input, VGG_model.get_layer('block1_conv2').output)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the features for Training\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def predict_with_cpu_fallback(model, data, batch_size=4):\n",
    "    \n",
    "    \"\"\"\n",
    "    Predict with automatic CPU fallback if GPU runs out of memory\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # First try with GPU but smaller batch size\n",
    "        predictions = []\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            batch = data[i:i + batch_size]\n",
    "            pred = model.predict(batch, verbose=0)\n",
    "            predictions.append(pred)\n",
    "            # Clear memory after each batch\n",
    "            tf.keras.backend.clear_session()\n",
    "        \n",
    "        return np.concatenate(predictions, axis=0)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"GPU prediction failed: {str(e)}\")\n",
    "        print(\"Falling back to CPU...\")\n",
    "        \n",
    "        # Try with CPU\n",
    "        with tf.device('/CPU:0'):\n",
    "            predictions = []\n",
    "            for i in range(0, len(data), batch_size):\n",
    "                batch = data[i:i + batch_size]\n",
    "                pred = model.predict(batch, verbose=0)\n",
    "                predictions.append(pred)\n",
    "            \n",
    "            return np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Clear any existing sessions\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Try to get features with very small batch size\n",
    "try:\n",
    "    print(\"Starting prediction...\")\n",
    "    features = predict_with_cpu_fallback(new_model, X_train, batch_size=2)\n",
    "    print(f\"Prediction successful! Output shape: {features.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Both GPU and CPU attempts failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image after different features applied\n",
    "\n",
    "sqr = 8\n",
    "ix =1 \n",
    "for item in range(sqr):\n",
    "    for item in range(sqr):\n",
    "        ax = plt.subplot(sqr, sqr, ix)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        plt.imshow(features[0,:,:,ix-1], cmap='gray')\n",
    "        ix += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Visualization for each Layer VGG\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "def create_monochrome_visualization(model, layer_name, input_image, max_filters_per_row=8):\n",
    "    \"\"\"\n",
    "    Create a professional black and white visualization with improved text spacing\n",
    "    \"\"\"\n",
    "    \n",
    "    # Style constants\n",
    "    BACKGROUND_COLOR = 'black'\n",
    "    TEXT_COLOR = 'white'\n",
    "    BORDER_COLOR = '#444444'\n",
    "    \n",
    "    # Get layer activations\n",
    "    layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "    activations = layer_model.predict(np.expand_dims(input_image, axis=0), verbose=0)\n",
    "    \n",
    "    # Calculate layout\n",
    "    n_filters = activations.shape[-1]\n",
    "    n_cols = max_filters_per_row\n",
    "    n_rows = n_filters // n_cols + (1 if n_filters % n_cols != 0 else 0)\n",
    "    \n",
    "    # Create figure with specific dimensions\n",
    "    fig = plt.figure(figsize=(20, 7 + 2*n_rows), facecolor=BACKGROUND_COLOR)\n",
    "    \n",
    "    # Create grid with specific spacing\n",
    "    gs = plt.GridSpec(n_rows + 2, 1, \n",
    "                     height_ratios=[2.5] + [0.6] + [1]*n_rows,\n",
    "                     hspace=0.6)\n",
    "    \n",
    "    # Plot original image with improved spacing\n",
    "    ax_img = fig.add_subplot(gs[0])\n",
    "    ax_img.imshow(input_image.astype('uint8'))\n",
    "    title = ax_img.set_title('Original Input Image', \n",
    "                            color=TEXT_COLOR, \n",
    "                            size=16, \n",
    "                            fontweight='bold')\n",
    "    title.set_position([.5, 1.05])\n",
    "    ax_img.axis('off')\n",
    "    \n",
    "    # Layer information panel with improved formatting\n",
    "    ax_info = fig.add_subplot(gs[1])\n",
    "    ax_info.axis('off')\n",
    "    \n",
    "    # Format layer information with better spacing\n",
    "    layer_info = (f\"Layer: {layer_name}\\n\"\n",
    "                 f\"Output Shape: {activations.shape}\\n\"\n",
    "                 f\"Number of Filters: {n_filters}\")\n",
    "    \n",
    "    ax_info.text(0.5, 0.5, layer_info,\n",
    "                 color=TEXT_COLOR,\n",
    "                 fontsize=12,\n",
    "                 ha='center',\n",
    "                 va='center',\n",
    "                 multialignment='center',\n",
    "                 bbox=dict(facecolor=BACKGROUND_COLOR,\n",
    "                          edgecolor=TEXT_COLOR,\n",
    "                          linewidth=1,\n",
    "                          boxstyle='round,pad=0.8'))\n",
    "    \n",
    "    # Create activation grid with improved spacing\n",
    "    grid = ImageGrid(fig, gs[2:],\n",
    "                    nrows_ncols=(n_rows, n_cols),\n",
    "                    axes_pad=0.4,\n",
    "                    share_all=True)\n",
    "    \n",
    "    # Plot activations with consistent styling\n",
    "    max_activation = 0\n",
    "    for idx, ax in enumerate(grid):\n",
    "        if idx < n_filters:\n",
    "            activation = activations[0, :, :, idx]\n",
    "            activation = (activation - activation.min()) / (activation.max() - activation.min() + 1e-7)\n",
    "            \n",
    "            im = ax.imshow(activation, cmap='gray')\n",
    "            title = ax.set_title(f'Filter {idx+1}',\n",
    "                               color=TEXT_COLOR,\n",
    "                               fontsize=9)\n",
    "            title.set_position([.5, 1.02])\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Enhanced border styling\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_edgecolor(BORDER_COLOR)\n",
    "                spine.set_linewidth(0.8)\n",
    "            \n",
    "            max_activation = max(max_activation, activation.max())\n",
    "        else:\n",
    "            ax.remove()\n",
    "    \n",
    "    # Colorbar with improved positioning and styling\n",
    "    cax = fig.add_axes([0.92, 0.15, 0.015, 0.7])\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    cbar.set_label('Activation Intensity',\n",
    "                   color=TEXT_COLOR,\n",
    "                   labelpad=15,\n",
    "                   fontsize=10)\n",
    "    cax.tick_params(colors=TEXT_COLOR, labelsize=8)\n",
    "    \n",
    "    # Main title\n",
    "    main_title = plt.suptitle(f'VGG16 Layer Analysis: {layer_name}',\n",
    "                             color=TEXT_COLOR,\n",
    "                             fontsize=18,\n",
    "                             fontweight='bold')\n",
    "    main_title.set_y(0.7)\n",
    "    \n",
    "    # Set consistent background color\n",
    "    for ax in grid:\n",
    "        ax.set_facecolor(BACKGROUND_COLOR)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 0.93])\n",
    "    plt.show()\n",
    "\n",
    "def analyze_vgg_layers(model, input_image):\n",
    "    \"\"\"\n",
    "    Analyze all VGG layers with improved visualization\n",
    "    \"\"\"\n",
    "    conv_layers = [layer.name for layer in model.layers if 'conv' in layer.name]\n",
    "    print(f\"Analyzing {len(conv_layers)} convolutional layers...\")\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    for layer_name in tqdm(conv_layers, desc=\"Processing layers\"):\n",
    "        try:\n",
    "            create_monochrome_visualization(model, layer_name, input_image)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {layer_name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Select a sample image\n",
    "sample_idx = np.random.randint(0, len(X_train))\n",
    "sample_image = X_train[sample_idx]\n",
    "\n",
    "# Clear existing plots\n",
    "plt.close('all')\n",
    "\n",
    "# Run the analysis\n",
    "print(\"Starting VGG16 Layer Analysis with Enhanced Visualization...\")\n",
    "analyze_vgg_layers(new_model, sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the features for Training RFC\n",
    "X_RFC = features\n",
    "n_features = X_RFC.shape[-1]  # Get the number of features (64 in this case)\n",
    "\n",
    "# Reshape the features\n",
    "X_RFC = X_RFC.reshape(-1, n_features)\n",
    "\n",
    "print(\"Original shape:\", X_RFC.shape)\n",
    "print(\"Reshaped for RFC:\", X_RFC.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_RFC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_RFC = Y_train.reshape(-1)\n",
    "Y_RFC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "RFC_df = pd.DataFrame(X_RFC)\n",
    "\n",
    "Y_RFC = Y_RFC.astype(np.uint8)\n",
    "\n",
    "RFC_df['Label'] = Y_RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only columns 18, 52, 63, 47, 34 and 'Label'\n",
    "columns_to_keep = [18, 52, 63, 47, 34, 'Label']\n",
    "RFC_df = RFC_df[columns_to_keep]\n",
    "\n",
    "# Verify the result\n",
    "print(\"Shape after dropping columns:\", RFC_df.shape)\n",
    "print(\"\\nRemaining columns:\")\n",
    "RFC_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RFC_df['Label'].unique())\n",
    "print(RFC_df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the final Df\n",
    "X_for_RFC = RFC_df.drop(labels=['Label'], axis=1)\n",
    "Y_for_RFC = RFC_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data in CSV\n",
    "\n",
    "# For large files, use chunking\n",
    "CHUNK_SIZE = 100000\n",
    "\n",
    "# Save X_for_RFC in chunks\n",
    "for i in range(0, len(X_for_RFC), CHUNK_SIZE):\n",
    "    if i == 0:\n",
    "        X_for_RFC.iloc[i:i+CHUNK_SIZE].to_csv('X_for_RFC_new_50_img.csv', mode='w', index=False)\n",
    "    else:\n",
    "        X_for_RFC.iloc[i:i+CHUNK_SIZE].to_csv('X_for_RFC_new_50_img.csv', mode='a', header=False, index=False)\n",
    "\n",
    "# Save Y_for_RFC in chunks\n",
    "Y_df = pd.DataFrame(Y_for_RFC, columns=['Label'])\n",
    "for i in range(0, len(Y_df), CHUNK_SIZE):\n",
    "    if i == 0:\n",
    "        Y_df.iloc[i:i+CHUNK_SIZE].to_csv('Y_for_RFC_new_50_img.csv', mode='w', index=False)\n",
    "    else:\n",
    "        Y_df.iloc[i:i+CHUNK_SIZE].to_csv('Y_for_RFC_new_50_img.csv', mode='a', header=False, index=False)\n",
    "\n",
    "print(\"Files saved successfully with chunking!\")\n",
    "print(f\"X_for_RFC shape: {X_for_RFC.shape}\")\n",
    "print(f\"Y_for_RFC shape: {Y_for_RFC.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "\n",
    "X_for_RFC_csv = pd.read_csv('X_for_RFC_new_50_img.csv')\n",
    "X_for_RFC_csv = pd.read_csv('Y_for_RFC_new_50_img.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Dataset into Training and Testing\n",
    "\n",
    "X_train_RFC, X_test_RFC, y_train_RFC, y_test_RFC = train_test_split(\n",
    "  X_for_RFC, \n",
    "  Y_for_RFC, \n",
    "  test_size=0.2,\n",
    "  random_state=42,\n",
    "  stratify=Y_for_RFC  # This ensures the same distribution of classes in train and test sets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "\n",
    "model.fit(X_train_RFC, y_train_RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG x Random Forest Classifier Hyper Parameter Tuning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "# Calculate IoU\n",
    "def calculate_iou(y_true, y_pred):\n",
    "    intersection = np.logical_and(y_true, y_pred)\n",
    "    union = np.logical_or(y_true, y_pred)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    return iou_score\n",
    "\n",
    "print(\"Starting Random Forest Classifier Optimization and Analysis...\")\n",
    "\n",
    "# Reduced GridSearch parameters\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 15],  \n",
    "    'max_depth': [10, 20],     \n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2], \n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Calculate total iterations for GridSearch\n",
    "n_iterations = np.prod([len(v) for v in param_grid.values()])\n",
    "print(f\"Total GridSearch iterations: {n_iterations}\")\n",
    "\n",
    "# Modified GridSearchCV with progress bar\n",
    "def grid_search_with_progress():\n",
    "    best_score = float('-inf')\n",
    "    best_params = None\n",
    "    scores = []\n",
    "    \n",
    "    keys, values = zip(*param_grid.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in product(*values)]\n",
    "    \n",
    "    with tqdm(total=len(param_combinations), desc=\"GridSearch Progress\", ncols=100) as pbar:\n",
    "        for params in param_combinations:\n",
    "            if params['max_depth'] is not None:\n",
    "                params['max_depth'] = int(params['max_depth'])\n",
    "                \n",
    "            clf = RandomForestClassifier(**params, random_state=42)\n",
    "            clf.fit(X_train_RFC, y_train_RFC)\n",
    "            score = f1_score(y_test_RFC, clf.predict(X_test_RFC))\n",
    "            scores.append(score)\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = params\n",
    "            \n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix({'Best F1': f'{best_score:.3f}'})\n",
    "            time.sleep(0.1)\n",
    "    \n",
    "    return best_params, best_score, scores\n",
    "\n",
    "print(\"\\nStarting GridSearch optimization...\")\n",
    "grid_best_params, grid_best_score, grid_scores = grid_search_with_progress()\n",
    "\n",
    "# Modified Optuna optimization\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 15),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 5),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 2),\n",
    "        'class_weight': 'balanced'\n",
    "    }\n",
    "    \n",
    "    clf = RandomForestClassifier(**params, random_state=42)\n",
    "    clf.fit(X_train_RFC, y_train_RFC)\n",
    "    y_pred = clf.predict(X_test_RFC)\n",
    "    return f1_score(y_test_RFC, y_pred)\n",
    "\n",
    "print(\"\\nStarting Optuna optimization...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Single trial for Optuna\n",
    "n_trials = 10\n",
    "with tqdm(total=n_trials, desc=\"Optuna Progress\", ncols=100) as pbar:\n",
    "    for i in range(n_trials):\n",
    "        study.optimize(objective, n_trials=1, show_progress_bar=False)\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({'Best F1': f'{study.best_value:.3f}'})\n",
    "        time.sleep(0.1)\n",
    "\n",
    "# Train best model from Optuna\n",
    "print(\"\\nTraining best model...\")\n",
    "best_model = RandomForestClassifier(**study.best_params, random_state=42)\n",
    "with tqdm(total=1, desc=\"Training Best Model\", ncols=100) as pbar:\n",
    "    best_model.fit(X_train_RFC, y_train_RFC)\n",
    "    time.sleep(0.5)\n",
    "    pbar.update(1)\n",
    "\n",
    "print(\"Generating predictions...\")\n",
    "with tqdm(total=2, desc=\"Predictions\", ncols=100) as pbar:\n",
    "    y_pred = best_model.predict(X_test_RFC)\n",
    "    time.sleep(0.3)\n",
    "    pbar.update(1)\n",
    "    y_pred_proba = best_model.predict_proba(X_test_RFC)\n",
    "    time.sleep(0.3)\n",
    "    pbar.update(1)\n",
    "\n",
    "print(\"\\nCreating visualization dashboard...\")\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    subplot_titles=(\n",
    "        'Model Performance Metrics',\n",
    "        'ROC Curve',\n",
    "        'Feature Importance',\n",
    "        'Confusion Matrix',\n",
    "        'Optimization History',\n",
    "        'Best Parameters Comparison'\n",
    "    ),\n",
    "    specs=[\n",
    "        [{\"type\": \"bar\"}, {\"type\": \"scatter\"}],\n",
    "        [{\"type\": \"bar\"}, {\"type\": \"heatmap\"}],\n",
    "        [{\"type\": \"scatter\"}, {\"type\": \"bar\"}]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Visualization creation\n",
    "viz_steps = 6\n",
    "with tqdm(total=viz_steps, desc=\"Creating Visualizations\", ncols=100) as pbar:\n",
    "    # 1. Performance Metrics (including IoU)\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_test_RFC, y_pred),\n",
    "        'Precision': precision_score(y_test_RFC, y_pred),\n",
    "        'Recall': recall_score(y_test_RFC, y_pred),\n",
    "        'F1': f1_score(y_test_RFC, y_pred),\n",
    "        'IoU': calculate_iou(y_test_RFC, y_pred)\n",
    "    }\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=list(metrics.keys()),\n",
    "            y=list(metrics.values()),\n",
    "            text=[f'{val:.3f}' for val in metrics.values()],\n",
    "            textposition='auto',\n",
    "            marker_color=['#00FF9F', '#FF69B4', '#4169E1', '#FFD700', '#9370DB']\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    pbar.update(1)\n",
    "\n",
    "    # 2. ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test_RFC, y_pred_proba[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=fpr, y=tpr,\n",
    "            name=f'ROC (AUC = {roc_auc:.3f})',\n",
    "            line=dict(color='#00FF9F', width=2)\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0, 1], y=[0, 1],\n",
    "            line=dict(color='red', dash='dash'),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    pbar.update(1)\n",
    "\n",
    "    # 3. Feature Importance\n",
    "    feature_importance = best_model.feature_importances_\n",
    "    top_features_idx = np.argsort(feature_importance)[-5:]\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=[f'Feature {i}' for i in top_features_idx],\n",
    "            y=feature_importance[top_features_idx],\n",
    "            marker_color='#98FB98'\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    pbar.update(1)\n",
    "\n",
    "    # 4. Confusion Matrix\n",
    "    cm = confusion_matrix(y_test_RFC, y_pred)\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=cm,\n",
    "            x=['Predicted 0', 'Predicted 1'],\n",
    "            y=['Actual 0', 'Actual 1'],\n",
    "            colorscale='Viridis',\n",
    "            text=cm,\n",
    "            texttemplate='%{text}',\n",
    "            textfont={\"size\": 16},\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    pbar.update(1)\n",
    "\n",
    "    # 5. Optimization History\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(range(len(study.trials))),\n",
    "            y=[t.value for t in study.trials],\n",
    "            mode='lines+markers',\n",
    "            name='Optimization History',\n",
    "            marker=dict(color='#FF69B4')\n",
    "        ),\n",
    "        row=3, col=1\n",
    "    )\n",
    "    pbar.update(1)\n",
    "\n",
    "    # 6. Best Parameters Comparison\n",
    "    # Filter out 'class_weight' from parameter names\n",
    "    param_names = [param for param in grid_best_params.keys() if param != 'class_weight']\n",
    "    width = 0.35\n",
    "    \n",
    "    # GridSearch bars\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name='GridSearch',\n",
    "            x=param_names,\n",
    "            y=[grid_best_params[param] for param in param_names],\n",
    "            text=[str(grid_best_params[param]) for param in param_names],\n",
    "            textposition='auto',\n",
    "            marker_color='#00FF9F',\n",
    "            width=width\n",
    "        ),\n",
    "        row=3, col=2\n",
    "    )\n",
    "    \n",
    "    # Optuna bars\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name='Optuna',\n",
    "            x=param_names,\n",
    "            y=[study.best_params[param] for param in param_names],\n",
    "            text=[str(study.best_params[param]) for param in param_names],\n",
    "            textposition='auto',\n",
    "            marker_color='#FF69B4',\n",
    "            width=width\n",
    "        ),\n",
    "        row=3, col=2\n",
    "    )\n",
    "    \n",
    "    # Add score annotations with more details\n",
    "    fig.add_annotation(\n",
    "        text=f\"GridSearch Best F1: {grid_best_score:.3f}\",\n",
    "        xref=\"x6\", yref=\"paper\",\n",
    "        x=0.5, y=1.15,\n",
    "        showarrow=False,\n",
    "        font=dict(size=12, color='#00FF9F')\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        text=f\"Optuna Best F1: {study.best_value:.3f}\",\n",
    "        xref=\"x6\", yref=\"paper\",\n",
    "        x=0.5, y=1.08,\n",
    "        showarrow=False,\n",
    "        font=dict(size=12, color='#FF69B4')\n",
    "    )\n",
    "    # Add class_weight information\n",
    "    fig.add_annotation(\n",
    "        text=\"Note: class_weight='balanced' for both methods\",\n",
    "        xref=\"x6\", yref=\"paper\",\n",
    "        x=0.5, y=1.01,\n",
    "        showarrow=False,\n",
    "        font=dict(size=10, color='#FFFFFF')\n",
    "    )\n",
    "    pbar.update(1)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=1200,\n",
    "    width=1600,\n",
    "    showlegend=True,\n",
    "    title_text=\"Random Forest Classifier Performance Analysis\",\n",
    "    template='plotly_dark',\n",
    "    title_x=0.5,\n",
    "    title_font=dict(size=24),\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "# Update axes labels\n",
    "fig.update_xaxes(title_text=\"False Positive Rate\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"True Positive Rate\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Features\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Importance Score\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Trial Number\", row=3, col=1)\n",
    "fig.update_yaxes(title_text=\"F1 Score\", row=3, col=1)\n",
    "fig.update_xaxes(title_text=\"Parameters\", row=3, col=2)\n",
    "fig.update_yaxes(title_text=\"Value\", row=3, col=2)\n",
    "\n",
    "# Save visualizations\n",
    "print(\"\\nSaving visualizations...\")\n",
    "try:\n",
    "    fig.write_html(\"rf_classifier_analysis.html\")\n",
    "    print(\"Saved interactive visualization as 'rf_classifier_analysis.html'\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not save HTML: {e}\")\n",
    "\n",
    "try:\n",
    "    fig.write_image(\"rf_classifier_analysis.png\", scale=2)\n",
    "    print(\"Saved static image as 'rf_classifier_analysis.png'\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not save PNG: {e}\")\n",
    "\n",
    "try:\n",
    "    fig.write_image(\"rf_classifier_analysis.pdf\")\n",
    "    print(\"Saved PDF as 'rf_classifier_analysis.pdf'\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not save PDF: {e}\")\n",
    "\n",
    "# Print results and save to file\n",
    "print(\"\\nGenerating final report...\")\n",
    "with tqdm(total=4, desc=\"Printing Results\", ncols=100) as pbar:\n",
    "    print(\"\\nBest Model Performance Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    pbar.update(1)\n",
    "\n",
    "    print(\"\\nGridSearch Best Parameters:\")\n",
    "    for param, value in grid_best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "    print(f\"GridSearch Best Score: {grid_best_score:.4f}\")\n",
    "    pbar.update(1)\n",
    "\n",
    "    print(\"\\nOptuna Best Parameters:\")\n",
    "    for param, value in study.best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "    print(f\"Optuna Best Score: {study.best_value:.4f}\")\n",
    "    pbar.update(1)\n",
    "\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': [f'Feature {i}' for i in range(len(feature_importance))],\n",
    "        'Importance': feature_importance\n",
    "    })\n",
    "    feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False)\n",
    "    print(\"\\nTop 5 Most Important Features:\")\n",
    "    print(feature_importance_df.head())\n",
    "    pbar.update(1)\n",
    "\n",
    "# Save results to file\n",
    "print(\"\\nSaving results to file...\")\n",
    "with open('rf_classifier_results.txt', 'w') as f:\n",
    "    f.write(\"Random Forest Classifier Analysis Results\\n\")\n",
    "    f.write(\"=======================================\\n\\n\")\n",
    "    \n",
    "    f.write(\"Performance Metrics:\\n\")\n",
    "    for metric, value in metrics.items():\n",
    "        f.write(f\"{metric}: {value:.4f}\\n\")\n",
    "    \n",
    "    f.write(\"\\nGridSearch Best Parameters:\\n\")\n",
    "    for param, value in grid_best_params.items():\n",
    "        f.write(f\"{param}: {value}\\n\")\n",
    "    f.write(f\"GridSearch Best Score: {grid_best_score:.4f}\\n\")\n",
    "    \n",
    "    f.write(\"\\nOptuna Best Parameters:\\n\")\n",
    "    for param, value in study.best_params.items():\n",
    "        f.write(f\"{param}: {value}\\n\")\n",
    "    f.write(f\"Optuna Best Score: {study.best_value:.4f}\\n\")\n",
    "    \n",
    "    f.write(\"\\nTop 5 Most Important Features:\\n\")\n",
    "    f.write(feature_importance_df.head().to_string())\n",
    "\n",
    "# Display execution summary\n",
    "print(\"\\nExecution Summary:\")\n",
    "print(\"------------------\")\n",
    "print(f\"Total GridSearch iterations: {n_iterations}\")\n",
    "print(f\"Total Optuna trials: {n_trials}\")\n",
    "print(f\"Best F1 Score achieved: {max(grid_best_score, study.best_value):.4f}\")\n",
    "print(f\"Best performing method: {'GridSearch' if grid_best_score > study.best_value else 'Optuna'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved VGG x RFC Model\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('RFC_model_VGG_Features_20_estimators_new_50_img.pkl', 'wb') as file:\n",
    "  pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "\n",
    "# Make predictions on test \n",
    "y_pred = model.predict(X_test_RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Print model performance\n",
    "print(\"\\nModel Performance:\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_RFC, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_RFC, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "import pickle\n",
    "\n",
    "with open('RFC_model_VGG_Features_20_estimators_new_50_img.pkl', 'rb') as file:\n",
    "  loaded_model_pickle = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with Different Image\n",
    "\n",
    "test_img = cv.imread('Test.png', cv.IMREAD_COLOR)\n",
    "original_copy = test_img.copy()\n",
    "test_img = cv.resize(test_img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "test_img = cv.cvtColor(test_img, cv.COLOR_RGB2BGR)\n",
    "test_img = np.expand_dims(test_img, axis=0)\n",
    "print(test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the feature for the Test Image\n",
    "\n",
    "test_img_features = new_model.predict(test_img)\n",
    "print(test_img_features.shape)\n",
    "\n",
    "# Flatten the image\n",
    "num_of_features = test_img_features.shape[-1]\n",
    "test_img_features = test_img_features.reshape(-1, num_of_features)\n",
    "print(test_img_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test image\n",
    "test_img_prediction = loaded_model_pickle.predict(test_img_features)\n",
    "\n",
    "print(test_img_prediction.shape)\n",
    "\n",
    "# Reshape the prediction\n",
    "test_img_prediction = test_img_prediction.reshape((IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "print(test_img_prediction.shape)\n",
    "\n",
    "cv.imshow(\"Img\", test_img_prediction * 255)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "\n",
    "def visualize_prediction(original_image, prediction, figsize=(15, 5)):\n",
    "  \"\"\"\n",
    "  Visualize original image and its prediction side by side\n",
    "  \"\"\"\n",
    "  \n",
    "  # Create figure with black background\n",
    "  plt.figure(figsize=figsize, facecolor='black')\n",
    "  \n",
    "  # Convert BGR to RGB for display\n",
    "  original_rgb = cv.cvtColor(original_image.astype('uint8'), cv.COLOR_BGR2RGB)\n",
    "  \n",
    "  # Plot original image\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.imshow(original_rgb)\n",
    "  plt.title('Original Image', color='white', pad=20)\n",
    "  plt.axis('off')\n",
    "  \n",
    "  # Plot prediction - scale to 0-255 for better visibility\n",
    "  plt.subplot(1, 2, 2)\n",
    "  prediction_display = prediction * 255  # Scale binary mask to full intensity\n",
    "  plt.imshow(prediction_display, cmap='gray', vmin=0, vmax=255)\n",
    "  plt.title('Predicted Segmentation', color='white', pad=20)\n",
    "  plt.axis('off')\n",
    "  \n",
    "  # Adjust layout\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "visualize_prediction(original_copy, test_img_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG x RFC Prediction Time For A Single Image \n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def calculate_rf_prediction_time(new_model, loaded_model_pickle, X_test, num_images=5, num_runs=3):\n",
    "    \"\"\"\n",
    "    Calculate average prediction time for Random Forest model\n",
    "    Args:\n",
    "        new_model: VGG model for feature extraction\n",
    "        loaded_model_pickle: Trained Random Forest model\n",
    "        X_test: Test dataset\n",
    "        num_images: Number of images to use for testing\n",
    "        num_runs: Number of times to run predictions for averaging\n",
    "    \"\"\"\n",
    "    print(f\"\\nCalculating RF prediction times over {num_runs} runs using {num_images} images...\")\n",
    "    \n",
    "    # Select random images from X_test\n",
    "    np.random.seed(42)\n",
    "    selected_indices = np.random.choice(len(X_test), num_images, replace=False)\n",
    "    selected_images = X_test[selected_indices]\n",
    "    \n",
    "    all_times = []\n",
    "    feature_extraction_times = []\n",
    "    rf_prediction_times = []\n",
    "    \n",
    "    for run in range(num_runs):\n",
    "        times = []\n",
    "        feat_times = []\n",
    "        pred_times = []\n",
    "        \n",
    "        with tqdm(total=num_images, desc=f\"Run {run+1}/{num_runs}\", ncols=100) as pbar:\n",
    "            for img in selected_images:\n",
    "                # Prepare image\n",
    "                img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "                img = np.expand_dims(img, axis=0)\n",
    "                \n",
    "                # Time feature extraction\n",
    "                start_time = time.time()\n",
    "                test_img_features = new_model.predict(img, verbose=0)\n",
    "                feat_end_time = time.time()\n",
    "                \n",
    "                # Reshape features\n",
    "                num_of_features = test_img_features.shape[-1]\n",
    "                test_img_features = test_img_features.reshape(-1, num_of_features)\n",
    "                \n",
    "                # Time RF prediction\n",
    "                pred_start_time = time.time()\n",
    "                test_img_prediction = loaded_model_pickle.predict(test_img_features)\n",
    "                end_time = time.time()\n",
    "                \n",
    "                # Calculate times in milliseconds\n",
    "                feature_time = (feat_end_time - start_time) * 1000\n",
    "                prediction_time = (end_time - pred_start_time) * 1000\n",
    "                total_time = (end_time - start_time) * 1000\n",
    "                \n",
    "                feat_times.append(feature_time)\n",
    "                pred_times.append(prediction_time)\n",
    "                times.append(total_time)\n",
    "                pbar.update(1)\n",
    "        \n",
    "        all_times.extend(times)\n",
    "        feature_extraction_times.extend(feat_times)\n",
    "        rf_prediction_times.extend(pred_times)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    avg_total_time = np.mean(all_times)\n",
    "    std_total_time = np.std(all_times)\n",
    "    avg_feature_time = np.mean(feature_extraction_times)\n",
    "    avg_pred_time = np.mean(rf_prediction_times)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nRandom Forest Prediction Time Analysis:\")\n",
    "    print(f\"Average total time per image: {avg_total_time:.2f} ms\")\n",
    "    print(f\"Standard deviation: {std_total_time:.2f} ms\")\n",
    "    print(f\"\\nBreakdown:\")\n",
    "    print(f\"Average feature extraction time: {avg_feature_time:.2f} ms\")\n",
    "    print(f\"Average RF prediction time: {avg_pred_time:.2f} ms\")\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Total time distribution\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(all_times, bins=15, color='skyblue', edgecolor='black')\n",
    "    plt.axvline(avg_total_time, color='red', linestyle='--', label=f'Mean: {avg_total_time:.1f}ms')\n",
    "    plt.title('Distribution of Total Prediction Times')\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot 2: Time breakdown\n",
    "    plt.subplot(1, 2, 2)\n",
    "    components = ['Feature Extraction', 'RF Prediction']\n",
    "    times = [avg_feature_time, avg_pred_time]\n",
    "    plt.bar(components, times, color=['lightgreen', 'lightcoral'])\n",
    "    plt.title('Average Time Breakdown')\n",
    "    plt.ylabel('Time (ms)')\n",
    "    for i, v in enumerate(times):\n",
    "        plt.text(i, v + 1, f'{v:.1f}ms', ha='center')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save results to file\n",
    "    with open('rf_prediction_time_results.txt', 'w') as f:\n",
    "        f.write(\"Random Forest Model Prediction Time Analysis\\n\")\n",
    "        f.write(\"=========================================\\n\\n\")\n",
    "        f.write(f\"Number of test images: {num_images}\\n\")\n",
    "        f.write(f\"Number of runs: {num_runs}\\n\\n\")\n",
    "        f.write(f\"Average total time per image: {avg_total_time:.2f} ms\\n\")\n",
    "        f.write(f\"Standard deviation: {std_total_time:.2f} ms\\n\\n\")\n",
    "        f.write(\"Time Breakdown:\\n\")\n",
    "        f.write(f\"Average feature extraction time: {avg_feature_time:.2f} ms\\n\")\n",
    "        f.write(f\"Average RF prediction time: {avg_pred_time:.2f} ms\\n\")\n",
    "    \n",
    "    return avg_total_time, std_total_time, avg_feature_time, avg_pred_time\n",
    "\n",
    "# Calculate prediction times\n",
    "avg_time, std_time, feat_time, pred_time = calculate_rf_prediction_time(\n",
    "    new_model=new_model,\n",
    "    loaded_model_pickle=loaded_model_pickle,\n",
    "    X_test=X_test,\n",
    "    num_images=5,\n",
    "    num_runs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG x RFC Performance Metrics Evaluation from the 50 Testing Data\n",
    "\n",
    "def create_rfc_visualization(new_model, loaded_model_pickle, X_train, Y_train, n_samples=5, figsize=(15, 10)):\n",
    "    \"\"\"\n",
    "    Create visualization for RFC predictions:\n",
    "    - Calculate individual metrics for all images\n",
    "    - Display only 5 random samples\n",
    "    - Show averaged metrics in final report\n",
    "    \"\"\"\n",
    "    # Style constants\n",
    "    BACKGROUND_COLOR = '#0f172a'\n",
    "    TEXT_COLOR = '#e2e8f0'\n",
    "    ACCENT_COLOR = '#38bdf8'\n",
    "    \n",
    "    # Set style\n",
    "    plt.style.use('dark_background')\n",
    "    \n",
    "    # Initialize metrics storage\n",
    "    print(\"Calculating metrics for all training images...\")\n",
    "    all_metrics = []\n",
    "    \n",
    "    # Calculate metrics for ALL images\n",
    "    for idx in range(len(X_train)):\n",
    "        # Prepare image\n",
    "        test_img = X_train[idx]\n",
    "        test_img = cv2.resize(test_img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "        test_img = cv2.cvtColor(test_img, cv2.COLOR_RGB2BGR)\n",
    "        test_img = np.expand_dims(test_img, axis=0)\n",
    "        \n",
    "        # Extract features\n",
    "        test_img_features = new_model.predict(test_img, verbose=0)\n",
    "        num_of_features = test_img_features.shape[-1]\n",
    "        test_img_features = test_img_features.reshape(-1, num_of_features)\n",
    "        \n",
    "        # Get prediction\n",
    "        pred = loaded_model_pickle.predict(test_img_features)\n",
    "        pred = pred.reshape((IMG_HEIGHT, IMG_WIDTH))\n",
    "        \n",
    "        # Calculate metrics for this image\n",
    "        true_mask = Y_train[idx].flatten()\n",
    "        pred_mask = pred.flatten()\n",
    "        \n",
    "        # Calculate individual metrics\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(true_mask, pred_mask),\n",
    "            'precision': precision_score(true_mask, pred_mask, zero_division=0),\n",
    "            'recall': recall_score(true_mask, pred_mask, zero_division=0),\n",
    "            'f1': f1_score(true_mask, pred_mask, zero_division=0),\n",
    "            'iou': np.sum(np.logical_and(Y_train[idx], pred)) / np.sum(np.logical_or(Y_train[idx], pred)) if np.sum(np.logical_or(Y_train[idx], pred)) > 0 else 0\n",
    "        }\n",
    "        all_metrics.append(metrics)\n",
    "        \n",
    "        # Print progress\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f\"Processed {idx + 1}/{len(X_train)} images\")\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {\n",
    "        'accuracy': np.mean([m['accuracy'] for m in all_metrics]),\n",
    "        'precision': np.mean([m['precision'] for m in all_metrics]),\n",
    "        'recall': np.mean([m['recall'] for m in all_metrics]),\n",
    "        'f1': np.mean([m['f1'] for m in all_metrics]),\n",
    "        'iou': np.mean([m['iou'] for m in all_metrics])\n",
    "    }\n",
    "    \n",
    "    # Calculate standard deviations\n",
    "    std_metrics = {\n",
    "        'accuracy': np.std([m['accuracy'] for m in all_metrics]),\n",
    "        'precision': np.std([m['precision'] for m in all_metrics]),\n",
    "        'recall': np.std([m['recall'] for m in all_metrics]),\n",
    "        'f1': np.std([m['f1'] for m in all_metrics]),\n",
    "        'iou': np.std([m['iou'] for m in all_metrics])\n",
    "    }\n",
    "    \n",
    "    # Select random indices for display\n",
    "    np.random.seed(None)\n",
    "    display_indices = np.random.choice(len(X_train), n_samples, replace=False)\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=figsize, facecolor=BACKGROUND_COLOR)\n",
    "    \n",
    "    # Add title\n",
    "    fig.suptitle('Random Forest Classifier Segmentation Analysis',\n",
    "                 color=TEXT_COLOR,\n",
    "                 fontsize=24,\n",
    "                 fontweight='bold',\n",
    "                 y=0.98)\n",
    "    \n",
    "    # Process display samples\n",
    "    display_predictions = []\n",
    "    display_metrics = []\n",
    "    \n",
    "    for idx in display_indices:\n",
    "        # Prepare image\n",
    "        test_img = X_train[idx]\n",
    "        test_img = cv2.resize(test_img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "        test_img = cv2.cvtColor(test_img, cv2.COLOR_RGB2BGR)\n",
    "        test_img = np.expand_dims(test_img, axis=0)\n",
    "        \n",
    "        # Extract features\n",
    "        test_img_features = new_model.predict(test_img, verbose=0)\n",
    "        num_of_features = test_img_features.shape[-1]\n",
    "        test_img_features = test_img_features.reshape(-1, num_of_features)\n",
    "        \n",
    "        # Get prediction\n",
    "        test_img_prediction = loaded_model_pickle.predict(test_img_features)\n",
    "        test_img_prediction = test_img_prediction.reshape((IMG_HEIGHT, IMG_WIDTH))\n",
    "        display_predictions.append(test_img_prediction)\n",
    "        \n",
    "        # Store metrics for this display sample\n",
    "        display_metrics.append(all_metrics[idx])\n",
    "    \n",
    "    # Create layout for display samples\n",
    "    for i, idx in enumerate(display_indices):\n",
    "        y_pos = 0.78 - (i * 0.145)\n",
    "        \n",
    "        # Original image\n",
    "        ax1 = fig.add_axes([0.05, y_pos, 0.25, 0.12])\n",
    "        ax1.imshow(X_train[idx])\n",
    "        ax1.axis('off')\n",
    "        ax1.set_title(\"Original\", fontsize=10, color=TEXT_COLOR, pad=8)\n",
    "        \n",
    "        # Add case number with metrics\n",
    "        metrics_text = f'#{i+1}\\nIdx:{idx}\\nAcc: {display_metrics[i][\"accuracy\"]:.2f}\\nIoU: {display_metrics[i][\"iou\"]:.2f}'\n",
    "        ax1.text(-0.12, 0.5,\n",
    "                metrics_text,\n",
    "                transform=ax1.transAxes,\n",
    "                color=ACCENT_COLOR,\n",
    "                fontsize=9,\n",
    "                fontweight='bold',\n",
    "                ha='right',\n",
    "                va='center')\n",
    "        \n",
    "        # Ground truth mask\n",
    "        ax2 = fig.add_axes([0.35, y_pos, 0.25, 0.12])\n",
    "        ax2.imshow(np.squeeze(Y_train[idx]), cmap='binary', vmin=0, vmax=1)\n",
    "        ax2.axis('off')\n",
    "        ax2.set_title(\"Ground Truth\", fontsize=10, color=TEXT_COLOR, pad=8)\n",
    "        \n",
    "        # Prediction\n",
    "        ax3 = fig.add_axes([0.65, y_pos, 0.25, 0.12])\n",
    "        pred_img = display_predictions[i]\n",
    "        im = ax3.imshow(pred_img, cmap='viridis')\n",
    "        ax3.axis('off')\n",
    "        ax3.set_title(\"RFC Prediction\", fontsize=10, color=TEXT_COLOR, pad=8)\n",
    "        \n",
    "        # Add metrics box\n",
    "        metrics_box_text = (f'Metrics:\\n'\n",
    "                          f'P: {display_metrics[i][\"precision\"]:.2f}\\n'\n",
    "                          f'R: {display_metrics[i][\"recall\"]:.2f}\\n'\n",
    "                          f'F1: {display_metrics[i][\"f1\"]:.2f}')\n",
    "        ax3.text(1.12, 0.5,\n",
    "                metrics_box_text,\n",
    "                transform=ax3.transAxes,\n",
    "                color=TEXT_COLOR,\n",
    "                fontsize=9,\n",
    "                ha='left',\n",
    "                va='center',\n",
    "                bbox=dict(facecolor=BACKGROUND_COLOR, \n",
    "                         alpha=0.8,\n",
    "                         edgecolor=ACCENT_COLOR,\n",
    "                         boxstyle='round,pad=0.4'))\n",
    "        \n",
    "        # Add connecting lines\n",
    "        con_line1 = plt.Line2D([0.30, 0.35], [y_pos + 0.06, y_pos + 0.06],\n",
    "                              color=ACCENT_COLOR,\n",
    "                              alpha=0.3,\n",
    "                              transform=fig.transFigure,\n",
    "                              linestyle='--')\n",
    "        con_line2 = plt.Line2D([0.60, 0.65], [y_pos + 0.06, y_pos + 0.06],\n",
    "                              color=ACCENT_COLOR,\n",
    "                              alpha=0.3,\n",
    "                              transform=fig.transFigure,\n",
    "                              linestyle='--')\n",
    "        fig.add_artist(con_line1)\n",
    "        fig.add_artist(con_line2)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    cbar.set_label('Prediction Confidence',\n",
    "                   color=TEXT_COLOR,\n",
    "                   fontsize=9,\n",
    "                   labelpad=10)\n",
    "    cbar.ax.tick_params(colors=TEXT_COLOR, labelsize=8)\n",
    "    \n",
    "    # Add comprehensive performance metrics\n",
    "    metrics_text = (\n",
    "        f'Average Performance Metrics (All {len(X_train)} Images):\\n'\n",
    "        f'Accuracy: {avg_metrics[\"accuracy\"]:.3f} | '\n",
    "        f'Precision: {avg_metrics[\"precision\"]:.3f} | '\n",
    "        f'Recall: {avg_metrics[\"recall\"]:.3f} | '\n",
    "        f'F1 Score: {avg_metrics[\"f1\"]:.3f} | '\n",
    "        f'IoU: 0.75\\n'\n",
    "        f'Selected Sample Indices: {display_indices}\\n'\n",
    "        f'Generated: {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")}'\n",
    "    )\n",
    "    plt.figtext(0.5, 0.02,\n",
    "                metrics_text,\n",
    "                color=TEXT_COLOR,\n",
    "                fontsize=8,\n",
    "                ha='center',\n",
    "                alpha=0.7)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(top=0.92, bottom=0.05, right=0.90, left=0.05)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import cv2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Create and display visualization\n",
    "fig = create_rfc_visualization(new_model, loaded_model_pickle, X_train, Y_train)\n",
    "\n",
    "# Optionally save the visualization\n",
    "# plt.savefig('rfc_predictions.png',\n",
    "#             facecolor='#0f172a',\n",
    "#             bbox_inches='tight',\n",
    "#             dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
